import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import schedule
from datetime import datetime, timedelta
import gspread
from google.oauth2.service_account import Credentials
import logging
import os
import json
from io import StringIO

class PremierLeagueScraper:
    def __init__(self):
        """
        Frumstillir scraper-inn me√∞ √∂llum nau√∞synlegum stillingum
        """
        self.base_url = "https://fbref.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.setup_logging()
        self.setup_google_sheets()
        
    def setup_logging(self):
        """Setur upp logging til a√∞ fylgjast me√∞ hva√∞ er a√∞ gerast"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_google_sheets(self):
        """
        Setur upp tengingu vi√∞ Google Sheets
        Notar environment variable fyrir credentials
        """
        try:
            self.logger.info("üîç BYRJA √Å GOOGLE SHEETS UPPSETNINGU...")
            
            # Reynir a√∞ f√° credentials fr√° environment variable
            creds_json = os.environ.get('GOOGLE_CREDENTIALS_JSON')
            
            if creds_json:
                self.logger.info("‚úÖ FANN GOOGLE_CREDENTIALS_JSON environment variable")
                
                # B√Ωr til credentials fr√° JSON string
                creds_info = json.loads(creds_json)
                self.logger.info(f"üìß Service account email: {creds_info.get('client_email', 'EKKERT EMAIL')}")
                
                scope = [
                    "https://spreadsheets.google.com/feeds",
                    "https://www.googleapis.com/auth/drive"
                ]
                creds = Credentials.from_service_account_info(creds_info, scopes=scope)
                self.gc = gspread.authorize(creds)
                self.logger.info("‚úÖ GOOGLE SHEETS TENGING T√ìKST!")
                
                # Pr√≥fum tenginguna strax
                self.test_google_connection()
                
            else:
                self.logger.error("‚ùå ENGIN GOOGLE_CREDENTIALS_JSON environment variable!")
                # Fallback fyrir local testing
                if os.path.exists('credentials.json'):
                    self.logger.info("üìÅ Reyni local credentials.json skr√°...")
                    scope = [
                        "https://spreadsheets.google.com/feeds",
                        "https://www.googleapis.com/auth/drive"
                    ]
                    creds = Credentials.from_service_account_file('credentials.json', scopes=scope)
                    self.gc = gspread.authorize(creds)
                    self.logger.info("‚úÖ GOOGLE SHEETS TENGING T√ìKST (local)!")
                    self.test_google_connection()
                else:
                    self.logger.error("‚ùå ENGAR GOOGLE CREDENTIALS FUNDNAR!")
                    self.gc = None
                    
        except Exception as e:
            self.logger.error(f"üí• VILLA VI√ê GOOGLE SHEETS UPPSETNINGU: {e}")
            self.gc = None

    def test_google_connection(self):
        """Pr√≥far Google tengingu me√∞ √æv√≠ a√∞ lista sheets"""
        if self.gc is None:
            self.logger.error("‚ùå ENGIN GOOGLE TENGING TIL A√ê PR√ìFA!")
            return False
        
        try:
            self.logger.info("üß™ PR√ìFA GOOGLE TENGINGU...")
            
            # Reynir bara a√∞ lista sheets - √æarf ekki a√∞ b√∫a til n√Ωtt
            sheets = self.gc.list_spreadsheet_files()
            self.logger.info(f"‚úÖ GOOGLE TENGING VIRKAR - FANN {len(sheets)} SHEETS")
            
            return True
            
        except Exception as e:
            self.logger.error(f"üí• VILLA VI√ê TEST: {e}")
            return False
            
    def get_premier_league_table(self):
        """S√¶kir Premier League t√∂fluna"""
        try:
            self.logger.info("üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø S√ÜKI PREMIER LEAGUE T√ñFLU...")
            
            url = f"{self.base_url}/en/comps/9/Premier-League-Stats"
            response = requests.get(url, headers=self.headers)
            self.logger.info(f"üì° HTTP Status: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Finnur t√∂fluna
            table = soup.find('table', {'class': 'stats_table'})
            
            if table:
                # Notar pandas til a√∞ lesa t√∂fluna
                df = pd.read_html(StringIO(str(table)))[0]
                
                # Hreinsar t√∂flu
                if len(df.columns) > 1:
                    # Fjarl√¶gir multi-level headers ef til sta√∞ar
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = ['_'.join(col).strip() for col in df.columns.values]
                    
                    df['Last_Updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    self.logger.info(f"‚úÖ PL TAFLA: {len(df)} li√∞ fundin")
                    return df
            else:
                self.logger.error("‚ùå FANN EKKI PL T√ñFLU √Å S√ç√êUNNI")
                    
        except Exception as e:
            self.logger.error(f"üí• VILLA VI√ê PL T√ñFLU: {e}")
            return None
            
    def get_player_stats(self):
        """
        S√¶kir leikmannast√∂lfr√¶√∞i - mikilv√¶gt fyrir fantasy og ve√∞m√°l
        """
        try:
            self.logger.info("‚öΩ S√ÜKI LEIKMANNAST√ñLFR√Ü√êI...")
            
            # Byrjum √° grunnst√∂lfr√¶√∞i
            url = f"{self.base_url}/en/comps/9/stats/Premier-League-Stats"
            response = requests.get(url, headers=self.headers)
            self.logger.info(f"üì° HTTP Status: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Finnur player stats t√∂flu
            table = soup.find('table', {'id': 'stats_standard'})
            
            if table:
                df = pd.read_html(StringIO(str(table)))[0]
                
                # Hreinsar multi-level columns
                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = ['_'.join(col).strip() for col in df.columns.values]
                
                df['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self.logger.info(f"‚úÖ LEIKMANNAG√ñGN: {len(df)} leikmenn fundnir")
                return df
            else:
                self.logger.error("‚ùå FANN EKKI LEIKMANNAST√ñLFR√Ü√êI")
                
        except Exception as e:
            self.logger.error(f"üí• VILLA VI√ê LEIKMANNAG√ñGN: {e}")
            return None
            
    def get_fixtures_and_results(self):
        """
        S√¶kir leiki og ni√∞urst√∂√∞ur - mikilv√¶gt fyrir betting
        """
        try:
            self.logger.info("üìÖ S√ÜKI LEIKI OG NI√êURST√ñ√êUR...")
            
            url = f"{self.base_url}/en/comps/9/schedule/Premier-League-Fixtures"
            response = requests.get(url, headers=self.headers)
            self.logger.info(f"üì° HTTP Status: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            table = soup.find('table', {'class': 'stats_table'})
            if table:
                df = pd.read_html(StringIO(str(table)))[0]
                df['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self.logger.info(f"‚úÖ LEIKJAG√ñGN: {len(df)} leikir fundnir")
                return df
            else:
                self.logger.error("‚ùå FANN EKKI LEIKJAT√ñFLU")
                
        except Exception as e:
            self.logger.error(f"üí• VILLA VI√ê LEIKJAG√ñGN: {e}")
            return None
            
    def update_google_sheet(self, sheet_name, data, worksheet_name):
        """
        Uppf√¶rir Google Sheet me√∞ n√Ωjum g√∂gnum
        """
        if self.gc is None:
            self.logger.error("‚ùå ENGIN GOOGLE SHEETS TENGING")
            return
            
        try:
            self.logger.info(f"üìä UPPF√ÜRI {worksheet_name} √ç {sheet_name}...")
            
            # Opnar e√∞a b√Ωr til sheet
            try:
                sheet = self.gc.open(sheet_name)
                self.logger.info(f"‚úÖ OPNA√êI N√öVERANDI SHEET: {sheet.title}")
            except gspread.SpreadsheetNotFound:
                self.logger.info(f"üÜï B√ù TIL N√ùTT SHEET: {sheet_name}")
                sheet = self.gc.create(sheet_name)
                # Deilir me√∞ √æ√≠num email
                sheet.share('arnortumio@gmail.com', perm_type='user', role='owner')
                self.logger.info("‚úÖ SHEET DEILT ME√ê arnortumio@gmail.com")
                self.logger.info(f"üîó SHEET URL: {sheet.url}")
            except Exception as create_error:
                self.logger.error(f"üí• VILLA VI√ê A√ê B√öA TIL SHEET: {create_error}")
                # Reynum a√∞ nota √æitt pers√≥nulega Drive
                self.logger.info("üîÑ REYNI A√ê NOTA EXISTING SHEET...")
                try:
                    # B√Ωr til sheet me√∞ √∂√∞ru nafni
                    import random
                    backup_name = f"PL_Data_{random.randint(1000,9999)}"
                    sheet = self.gc.create(backup_name)
                    sheet.share('arnortumio@gmail.com', perm_type='user', role='owner')
                    self.logger.info(f"‚úÖ BACKUP SHEET B√öI√ê TIL: {sheet.url}")
                except Exception as e:
                    self.logger.error(f"üí• GETUR EKKI B√öI√ê TIL NEITT SHEET: {e}")
                    return
                
            # Opnar e√∞a b√Ωr til worksheet
            try:
                worksheet = sheet.worksheet(worksheet_name)
                worksheet.clear()  # Hreinsar eldri g√∂gn
                self.logger.info(f"‚ôªÔ∏è HREINSAR N√öVERANDI {worksheet_name}")
            except:
                self.logger.info(f"üÜï B√ù TIL N√ùJAN TAB: {worksheet_name}")
                worksheet = sheet.add_worksheet(title=worksheet_name, rows="1000", cols="30")
                
            # Setur g√∂gn inn
            if data is not None and not data.empty:
                # Breytir pandas DataFrame √≠ lista af listum
                data_list = [data.columns.tolist()] + data.values.tolist()
                
                # Takmarkar vi√∞ 1000 r√∂√∞um til a√∞ vera viss um a√∞ falla ekki
                if len(data_list) > 1000:
                    data_list = data_list[:1000]
                    
                worksheet.update('A1', data_list)
                self.logger.info(f"‚úÖ UPPF√ÜR√êI {worksheet_name} ME√ê {len(data)} R√ñ√êUM")
            else:
                self.logger.error(f"‚ùå ENGIN G√ñGN TIL A√ê UPPF√ÜRA √ç {worksheet_name}")
            
        except Exception as e:
            self.logger.error(f"üí• VILLA VI√ê UPPF√ÜRSLU √Å {worksheet_name}: {e}")
            
    def full_update(self):
        """
        Keyrir alla scraping og uppf√¶rir √∂ll sheet
        """
        self.logger.info("üöÄ BYRJA FULL UPDATE...")
        
        # Pr√≥far Google tengingu fyrst
        if not self.test_google_connection():
            self.logger.error("‚ùå GOOGLE TENGING VIRKAR EKKI - H√ÜTTI")
            return
        
        # S√¶kir √∂ll g√∂gn
        self.logger.info("üìä S√ÜKI √ñLL G√ñGN...")
        table_data = self.get_premier_league_table()
        player_data = self.get_player_stats()
        fixtures_data = self.get_fixtures_and_results()
        
        sheet_name = "PL_Fantasy_Data"
        
        # Uppf√¶rir Premier League t√∂flu
        if table_data is not None:
            self.update_google_sheet(sheet_name, table_data, "League_Table")
        else:
            self.logger.error("‚ùå ENGIN PL TAFLA TIL A√ê UPPF√ÜRA")
            
        # Uppf√¶rir leikmannag√∂gn
        if player_data is not None:
            self.update_google_sheet(sheet_name, player_data, "Player_Stats")
        else:
            self.logger.error("‚ùå ENGIN LEIKMANNAG√ñGN TIL A√ê UPPF√ÜRA")
                
        # Uppf√¶rir leiki og ni√∞urst√∂√∞ur
        if fixtures_data is not None:
            self.update_google_sheet(sheet_name, fixtures_data, "Fixtures_Results")
        else:
            self.logger.error("‚ùå ENGIN LEIKJAG√ñGN TIL A√ê UPPF√ÜRA")
            
        self.logger.info("üéâ FULL UPDATE LOKI√ê!")
        
    def run_once(self):
        """Keyrir eina uppf√¶rslu - gott fyrir testing"""
        self.full_update()
        
    def start_scheduler(self):
        """
        Setur upp t√≠masetningar fyrir uppf√¶rslur
        """
        # Uppf√¶rir √° hverjum 30 m√≠n
        schedule.every(30).minutes.do(self.full_update)
        
        # Uppf√¶rir einu sinni √° dag
        schedule.every().day.at("08:00").do(self.full_update)
        
        self.logger.info("‚è∞ SCHEDULER SETTUR UPP!")
        
        # Keyrir fyrstu uppf√¶rslu strax
        self.full_update()
        
        # Keyrir s√≠√∞an √≠ endalausa lykkju
        while True:
            schedule.run_pending()
            time.sleep(60)  # Athugar √° m√≠n√∫tu fresti

def run_web_server():
    """Keyrir einfaldan web server fyrir Render"""
    from http.server import HTTPServer, SimpleHTTPRequestHandler
    import threading
    
    class Handler(SimpleHTTPRequestHandler):
        def do_GET(self):
            self.send_response(200)
            self.send_header('Content-type', 'text/html')
            self.end_headers()
            
            html_content = """
            <!DOCTYPE html>
            <html>
            <head>
                <title>PL Scraper Status</title>
                <meta http-equiv="refresh" content="30">
            </head>
            <body>
                <h1>üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø Premier League Scraper</h1>
                <p><strong>Status:</strong> RUNNING! ‚úÖ</p>
                <p><strong>Check your Google Sheets for data:</strong></p>
                <ul>
                    <li>Sheet name: "PL_Fantasy_Data"</li>
                    <li>Tabs: League_Table, Player_Stats, Fixtures_Results</li>
                </ul>
                <p><em>This page refreshes every 30 seconds</em></p>
                <p><small>Deploy time: """ + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + """</small></p>
            </body>
            </html>
            """
            
            self.wfile.write(html_content.encode('utf-8'))

    port = int(os.environ.get('PORT', 8000))
    server = HTTPServer(('0.0.0.0', port), Handler)
    
    def start_server():
        print(f"üåê Web server running on port {port}")
        server.serve_forever()
    
    # Keyrir web server √≠ background thread
    thread = threading.Thread(target=start_server)
    thread.daemon = True
    thread.start()

def main():
    """
    A√∞alfall til a√∞ keyra scraper-inn
    """
    print("üöÄ BYRJA PREMIER LEAGUE SCRAPER...")
    
    scraper = PremierLeagueScraper()
    
    # Athugar hvort √æetta er production e√∞a development
    if os.environ.get('RENDER') or os.environ.get('RAILWAY_ENVIRONMENT'):
        print("‚òÅÔ∏è PRODUCTION MODE - KEYRI WEB SERVER OG SCHEDULER")
        # Production - keyrir web server og scheduler
        run_web_server()
        scraper.start_scheduler()
    else:
        # Development - keyrir bara einu sinni
        print("üíª DEVELOPMENT MODE - EINSKIPTIS UPPF√ÜRSLA")
        scraper.run_once()

if __name__ == "__main__":
    main()
