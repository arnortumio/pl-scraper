import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import schedule
from datetime import datetime
import gspread
from google.oauth2.service_account import Credentials
import logging
import os
import json
from io import StringIO

class PremierLeagueScraper:
    def __init__(self):
        """
        Frumstillir scraper-inn meÃ° Ã¶llum nauÃ°synlegum stillingum
        """
        self.base_url = "https://fbref.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.setup_logging()
        self.setup_google_sheets()
        
    def setup_logging(self):
        """Setur upp logging til aÃ° fylgjast meÃ° hvaÃ° er aÃ° gerast"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_google_sheets(self):
        """
        Setur upp tengingu viÃ° Google Sheets
        Notar environment variable fyrir credentials
        """
        try:
            self.logger.info("ğŸ” BYRJA Ã GOOGLE SHEETS UPPSETNINGU...")
            
            creds_json = os.environ.get('GOOGLE_CREDENTIALS_JSON')
            
            if creds_json:
                self.logger.info("âœ… FANN GOOGLE_CREDENTIALS_JSON environment variable")
                
                creds_info = json.loads(creds_json)
                self.logger.info(f"ğŸ“§ Service account email: {creds_info.get('client_email', 'EKKERT EMAIL')}")
                
                scope = [
                    "https://spreadsheets.google.com/feeds",
                    "https://www.googleapis.com/auth/drive"
                ]
                creds = Credentials.from_service_account_info(creds_info, scopes=scope)
                self.gc = gspread.authorize(creds)
                self.logger.info("âœ… GOOGLE SHEETS TENGING TÃ“KST!")
                
                self.test_google_connection()
                
            else:
                self.logger.error("âŒ ENGIN GOOGLE_CREDENTIALS_JSON environment variable!")
                if os.path.exists('credentials.json'):
                    self.logger.info("ğŸ“ Reyni local credentials.json skrÃ¡...")
                    scope = [
                        "https://spreadsheets.google.com/feeds",
                        "https://www.googleapis.com/auth/drive"
                    ]
                    creds = Credentials.from_service_account_file('credentials.json', scopes=scope)
                    self.gc = gspread.authorize(creds)
                    self.logger.info("âœ… GOOGLE SHEETS TENGING TÃ“KST (local)!")
                    self.test_google_connection()
                else:
                    self.logger.error("âŒ ENGAR GOOGLE CREDENTIALS FUNDNAR!")
                    self.gc = None
                    
        except Exception as e:
            self.logger.error(f"ğŸ’¥ VILLA VIÃ GOOGLE SHEETS UPPSETNINGU: {e}")
            self.gc = None

    def test_google_connection(self):
        """PrÃ³far Google tengingu meÃ° Ã¾vÃ­ aÃ° lista sheets"""
        if self.gc is None:
            self.logger.error("âŒ ENGIN GOOGLE TENGING TIL AÃ PRÃ“FA!")
            return False
        
        try:
            self.logger.info("ğŸ§ª PRÃ“FA GOOGLE TENGINGU...")
            
            sheets = self.gc.list_spreadsheet_files()
            self.logger.info(f"âœ… GOOGLE TENGING VIRKAR - FANN {len(sheets)} SHEETS")
            
            return True
            
        except Exception as e:
            self.logger.error(f"ğŸ’¥ VILLA VIÃ TEST: {e}")
            return False
            
    def get_premier_league_table(self):
        """SÃ¦kir Premier League tÃ¶fluna"""
        try:
            self.logger.info("ğŸ´ SÃ†KI PREMIER LEAGUE TÃ–FLU...")
            
            url = f"{self.base_url}/en/comps/9/Premier-League-Stats"
            
            time.sleep(2)
            response = self.session.get(url, timeout=30)
            self.logger.info(f"ğŸ“¡ HTTP Status: {response.status_code}")
            
            if response.status_code != 200:
                self.logger.error(f"âŒ BAD HTTP RESPONSE: {response.status_code}")
                return None
            
            soup = BeautifulSoup(response.content, 'html.parser')
            table = soup.find('table', {'class': 'stats_table'})
            
            if table:
                df = pd.read_html(StringIO(str(table)))[0]
                
                if len(df.columns) > 1:
                    if isinstance(df.columns, pd.MultiIndex):
                        df.columns = ['_'.join(col).strip() for col in df.columns.values]
                    
                    df['Last_Updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    self.logger.info(f"âœ… PL tafla fundin: {len(df)} liÃ°")
                    return df
            else:
                self.logger.error("âŒ FANN EKKI PL TÃ–FLU Ã SÃÃUNNI")
                    
        except Exception as e:
            self.logger.error(f"ğŸ’¥ VILLA VIÃ PL TÃ–FLU: {e}")
            return None
            
    def get_player_stats(self):
        """
        SÃ¦kir leikmannastÃ¶lfrÃ¦Ã°i - mikilvÃ¦gt fyrir fantasy og veÃ°mÃ¡l
        """
        try:
            self.logger.info("âš½ SÃ†KI LEIKMANNASTÃ–LFRÃ†ÃI...")
            
            url = f"{self.base_url}/en/comps/9/stats/Premier-League-Stats"
            response = self.session.get(url)
            self.logger.info(f"ğŸ“¡ HTTP Status: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            table = soup.find('table', {'id': 'stats_standard'})
            
            if table:
                df = pd.read_html(StringIO(str(table)))[0]
                
                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = ['_'.join(col).strip() for col in df.columns.values]
                
                df['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self.logger.info(f"âœ… Leikmenn fundnir: {len(df)}")
                return df
            else:
                self.logger.error("âŒ FANN EKKI LEIKMANNASTÃ–LFRÃ†ÃI")
                
        except Exception as e:
            self.logger.error(f"ğŸ’¥ VILLA VIÃ LEIKMANNAGÃ–GN: {e}")
            return None
            
    def get_fixtures_and_results(self):
        """
        SÃ¦kir leiki og niÃ°urstÃ¶Ã°ur - mikilvÃ¦gt fyrir betting
        """
        try:
            self.logger.info("ğŸ“… SÃ†KI LEIKI OG NIÃURSTÃ–ÃUR...")
            
            url = f"{self.base_url}/en/comps/9/schedule/Premier-League-Fixtures"
            response = self.session.get(url)
            self.logger.info(f"ğŸ“¡ HTTP Status: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            table = soup.find('table', {'class': 'stats_table'})
            if table:
                df = pd.read_html(StringIO(str(table)))[0]
                df['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self.logger.info(f"âœ… Leikir fundnir: {len(df)}")
                return df
            else:
                self.logger.error("âŒ FANN EKKI LEIKJATÃ–FLU")
                
        except Exception as e:
            self.logger.error(f"ğŸ’¥ VILLA VIÃ LEIKJAGÃ–GN: {e}")
            return None
            
    def update_google_sheet(self, sheet_name, data, worksheet_name):
        """
        UppfÃ¦rir Google Sheet meÃ° nÃ½jum gÃ¶gnum
        """
        if self.gc is None:
            self.logger.error("âŒ ENGIN GOOGLE SHEETS TENGING")
            return
            
        try:
            self.logger.info(f"ğŸ“Š UppfÃ¦ri {worksheet_name} Ã­ {sheet_name}...")
            
            try:
                sheet = self.gc.open(sheet_name)
                self.logger.info(f"âœ… OpnaÃ°i nÃºverandi sheet: {sheet.title}")
            except gspread.SpreadsheetNotFound:
                self.logger.info(f"ğŸ†• BÃ½ til nÃ½tt sheet: {sheet_name}")
                sheet = self.gc.create(sheet_name)
                sheet.share('arnortumio@gmail.com', perm_type='user', role='owner')
                self.logger.info("âœ… Sheet deilt meÃ° arnortumio@gmail.com")
                self.logger.info(f"ğŸ”— Sheet URL: {sheet.url}")
            except Exception as create_error:
                self.logger.error(f"ğŸ’¥ Villa viÃ° aÃ° bÃºa til sheet: {create_error}")
                self.logger.info("ğŸ”„ Reyni aÃ° nota existing sheet...")
                try:
                    import random
                    backup_name = f"PL_Data_{random.randint(1000,9999)}"
                    sheet = self.gc.create(backup_name)
                    sheet.share('arnortumio@gmail.com', perm_type='user', role='owner')
                    self.logger.info(f"âœ… Backup sheet bÃºiÃ° til: {sheet.url}")
                except Exception as e:
                    self.logger.error(f"ğŸ’¥ Getur ekki bÃºiÃ° til neitt sheet: {e}")
                    return
                
            try:
                worksheet = sheet.worksheet(worksheet_name)
                worksheet.clear()
                self.logger.info(f"â™»ï¸ Hreinsar nÃºverandi {worksheet_name}")
            except gspread.WorksheetNotFound:
                self.logger.info(f"ğŸ†• BÃ½ til nÃ½jan tab: {worksheet_name}")
                worksheet = sheet.add_worksheet(title=worksheet_name, rows="1000", cols="30")
                
            if data is not None and not data.empty:
                # LagaÃ°: FjarlÃ¦gja NaN til aÃ° forÃ°ast JSON villu Ã­ Google Sheets API
                data = data.fillna("")
                data_list = [data.columns.tolist()] + data.values.tolist()
                worksheet.update('A1', data_list)
                self.logger.info(f"âœ… UppfÃ¦rÃ°i {worksheet_name} meÃ° {len(data)} rÃ¶Ã°um.")
            else:
                self.logger.warning(f"âš ï¸ Engin gÃ¶gn til aÃ° uppfÃ¦ra Ã­ {worksheet_name}.")
            
        except Exception as e:
            self.logger.error(f"ğŸ’¥ Villa viÃ° uppfÃ¦rslu Ã¡ {worksheet_name}: {e}")
            
    def full_update(self):
        """
        Keyrir alla scraping og uppfÃ¦rir Ã¶ll sheet
        """
        self.logger.info("ğŸš€ Byrja fulla uppfÃ¦rslu...")
        
        if not self.test_google_connection():
            self.logger.error("âŒ Google tenging virkar ekki - hÃ¦tti")
            return
        
        self.logger.info("ğŸ“Š SÃ¦ki Ã¶ll gÃ¶gn...")
        table_data = self.get_premier_league_table()
        player_data = self.get_player_stats()
        fixtures_data = self.get_fixtures_and_results()
        
        sheet_name = "Premier_League_Data"
        
        self.update_google_sheet(sheet_name, table_data, "League_Table")
        self.update_google_sheet(sheet_name, player_data, "Player_Stats")
        self.update_google_sheet(sheet_name, fixtures_data, "Fixtures")
        
        self.logger.info("âœ… Full uppfÃ¦rsla loki")
        
    def start_scheduler(self):
        """
        Setur upp schedule til aÃ° keyra full_update tvisvar Ã¡ dag
        """
        self.logger.info("â° Scheduler settur upp.")
        schedule.every().day.at("08:00").do(self.full_update)
        schedule.every().day.at("20:00").do(self.full_update)
        
        self.logger.info("ğŸ•’ Scheduler keyrir nÃº...")
        while True:
            schedule.run_pending()
            time.sleep(1)
            

if __name__ == "__main__":
    scraper = PremierLeagueScraper()
    scraper.full_update()
    scraper.start_scheduler()
