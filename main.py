import cloudscraper
from bs4 import BeautifulSoup, Comment
import pandas as pd
import time
import schedule
from datetime import datetime
import gspread
from google.oauth2.service_account import Credentials
import logging
import os
import json
from io import StringIO
from http.server import HTTPServer, SimpleHTTPRequestHandler
import threading

class PremierLeagueScraper:
    def __init__(self):
        self.base_url = "https://fbref.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = cloudscraper.create_scraper()
        self.session.headers.update(self.headers)
        self.setup_logging()
        self.setup_google_sheets()

    def setup_logging(self):
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        self.logger = logging.getLogger(__name__)

    def setup_google_sheets(self):
        try:
            self.logger.info("üîç BYRJA √Å GOOGLE SHEETS UPPSETNINGU...")
            creds_json = os.environ.get('GOOGLE_CREDENTIALS_JSON')
            if creds_json:
                creds_info = json.loads(creds_json)
                scope = [
                    "https://spreadsheets.google.com/feeds",
                    "https://www.googleapis.com/auth/drive"
                ]
                creds = Credentials.from_service_account_info(creds_info, scopes=scope)
                self.gc = gspread.authorize(creds)
                self.logger.info("‚úÖ GOOGLE SHEETS TENGING T√ìKST!")
                self.test_google_connection()
            else:
                self.logger.error("‚ùå ENGIN GOOGLE_CREDENTIALS_JSON fundin!")
                self.gc = None
        except Exception as e:
            self.logger.error(f"üí• Villa vi√∞ Google Sheets uppsetningu: {e}")
            self.gc = None

    def test_google_connection(self):
        if not self.gc:
            self.logger.error("‚ùå Engin Google tenging til a√∞ pr√≥fa.")
            return False
        try:
            self.gc.list_spreadsheet_files()
            self.logger.info("‚úÖ GOOGLE TENGING VIRKAR")
            return True
        except Exception as e:
            self.logger.error(f"üí• Villa vi√∞ pr√≥fun: {e}")
            return False

    # --------------------------- FBref hj√°lparf√∂ll --------------------------- #
    def get_html_table(self, url, div_id=None, table_id=None):
        try:
            response = self.session.get(url, timeout=30)
            self.logger.info(f"üì° HTTP Status: {response.status_code} ({url})")
            if response.status_code != 200:
                return None
            soup = BeautifulSoup(response.text, 'html.parser')
            if div_id:
                div = soup.find('div', id=div_id)
                comment = div.find(string=lambda text: isinstance(text, Comment)) if div else None
                soup = BeautifulSoup(comment, 'html.parser') if comment else soup
            table = soup.find('table', {'id': table_id}) if table_id else soup.find('table', {'class': 'stats_table'})
            return table
        except Exception as e:
            self.logger.error(f"üí• Villa vi√∞ a√∞ s√¶kja t√∂flu: {e}")
            return None

    def get_premier_league_table(self):
        self.logger.info("üè¥ S√¶ki Premier League t√∂flu...")
        url = f"{self.base_url}/en/comps/9/Premier-League-Stats"
        table = self.get_html_table(url, div_id='all_results2024-2025_9_overall')
        if table:
            df = pd.read_html(str(table))[0]
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = ['_'.join(col).strip() for col in df.columns.values]
            df['Last_Updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            self.logger.info(f"‚úÖ PL tafla fundin: {len(df)} li√∞")
            return df
        self.logger.error("‚ùå Gat ekki fundi√∞ PL t√∂flu.")
        return None

    def get_player_stats(self):
        self.logger.info("‚öΩ S√¶ki leikmannastatist√≠k (FBref)...")
        url = f"{self.base_url}/en/comps/9/stats/Premier-League-Stats"
        table = self.get_html_table(url, div_id='all_stats_standard', table_id='stats_standard')
        if table:
            df = pd.read_html(str(table))[0]
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = ['_'.join(col).strip() for col in df.columns.values]
            df['Last_Updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            self.logger.info(f"‚úÖ Leikmenn fundnir (FBref): {len(df)}")
            return df
        self.logger.error("‚ùå Gat ekki fundi√∞ leikmannat√∂flu (FBref).")
        return None

    def get_fixtures_and_results(self):
        self.logger.info("üìÖ S√¶ki leikjauppl√Ωsingar (FBref)...")
        url = f"{self.base_url}/en/comps/9/schedule/Premier-League-Fixtures"
        table = self.get_html_table(url, div_id='all_sched_ks_3232_1')
        if table:
            df = pd.read_html(str(table))[0]
            df['Last_Updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            self.logger.info(f"‚úÖ Leikir fundnir (FBref): {len(df)}")
            return df
        self.logger.error("‚ùå Gat ekki fundi√∞ leikjat√∂flu (FBref).")
        return None

    # --------------------------- FPL hj√°lparf√∂ll ---------------------------- #
    def _json_get(self, url: str):
        """√ñrugg JSON bei√∞ni me√∞ sk√Ωrri villume√∞h√∂ndlun."""
        try:
            r = self.session.get(url, timeout=30)
            self.logger.info(f"üì° HTTP Status: {r.status_code} ({url})")
            r.raise_for_status()
            return r.json()
        except Exception as e:
            self.logger.error(f"üí• Villa vi√∞ JSON bei√∞ni √° {url}: {e}")
            return None

    def get_fpl_data(self):
        """
        S√¶kir *√∂ll* almenn FPL g√∂gn (√°n innskr√°ningar) og skilar sem dict af DataFrame-um.
        Notar:
          - https://fantasy.premierleague.com/api/bootstrap-static/
          - https://fantasy.premierleague.com/api/fixtures/
        """
        self.logger.info("üß© S√¶ki FPL g√∂gn (bootstrap-static, fixtures)...")

        bootstrap_url = "https://fantasy.premierleague.com/api/bootstrap-static/"
        fixtures_url = "https://fantasy.premierleague.com/api/fixtures/"

        data = self._json_get(bootstrap_url)
        fixtures = self._json_get(fixtures_url)

        if data is None:
            self.logger.error("‚ùå Engin FPL bootstrap g√∂gn fengust.")
            return {}

        dfs = {}
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        def dfize(obj, name):
            try:
                df = pd.json_normalize(obj)
                df['Last_Updated'] = timestamp
                dfs[name] = df
                self.logger.info(f"‚úÖ FPL {name}: {len(df)} ra√∞ir")
            except Exception as e:
                self.logger.error(f"üí• Gat ekki umbreytt {name} √≠ DataFrame: {e}")

        # Helstu listar √≠ bootstrap-static
        for key in [
            'events',            # Umfer√∞ir (Gameweeks)
            'teams',             # FPL-li√∞ (mapping vi√∞ PL-li√∞)
            'elements',          # Leikmenn me√∞ FPL-eiginleikum
            'element_types',     # St√∂√∞urnar (GK/DEF/MID/FWD)
            'phases',            # Fasal√Ωsingar (t.d. pre-season/season)
            'game_settings'      # Stillingar (einn hlut, ekki listi)
        ]:
            val = data.get(key)
            if val is None:
                self.logger.warning(f"‚ö†Ô∏è '{key}' fannst ekki √≠ FPL-g√∂gnum.")
                continue
            if isinstance(val, list):
                dfize(val, f"FPL_{key.capitalize()}")
            else:
                # Eitt JSON-obj ‚Äî setjum sem DataFrame me√∞ einni l√≠nu
                dfize([val], f"FPL_{key.capitalize()}")

        # Heildarfj√∂ldi leikmanna √≠ leiknum
        total_players = data.get('total_players')
        if total_players is not None:
            df_total = pd.DataFrame([{'total_players': total_players, 'Last_Updated': timestamp}])
            dfs['FPL_Total_Players'] = df_total
            self.logger.info("‚úÖ FPL Total_Players b√¶tt vi√∞")

        # Fixtures (allir leikir me√∞ FPL-ID, finished o.fl.)
        if fixtures is not None:
            try:
                df_fixt = pd.json_normalize(fixtures)
                df_fixt['Last_Updated'] = timestamp
                dfs['FPL_Fixtures_API'] = df_fixt
                self.logger.info(f"‚úÖ FPL Fixtures: {len(df_fixt)} ra√∞ir")
            except Exception as e:
                self.logger.error(f"üí• Gat ekki umbreytt fixtures √≠ DataFrame: {e}")

        return dfs

    # --------------------------- Sheets hj√°lparf√∂ll ------------------------- #
    def clean_data_for_sheets(self, data_list):
        """Skiptir √∫t NaN √≠ t√≥man streng fyrir Google Sheets."""
        cleaned = []
        for row in data_list:
            new_row = []
            for item in row:
                if pd.isna(item):
                    new_row.append("")
                else:
                    new_row.append(item)
            cleaned.append(new_row)
        return cleaned

    def update_google_sheet(self, sheet_name, data, worksheet_name):
        if self.gc is None:
            self.logger.error("‚ùå Engin Google Sheets tenging.")
            return
        try:
            try:
                sheet = self.gc.open(sheet_name)
            except gspread.SpreadsheetNotFound:
                sheet = self.gc.create(sheet_name)
                # Breyttu netfangi h√©r ef √æ√∫ vilt deila me√∞ √∂√∞rum
                sheet.share('your-email@example.com', perm_type='user', role='writer')

            try:
                worksheet = sheet.worksheet(worksheet_name)
                worksheet.clear()
            except gspread.WorksheetNotFound:
                # vel st√≥rt default pl√°ss
                worksheet = sheet.add_worksheet(title=worksheet_name, rows="5000", cols="200")

            if data is not None and not data.empty:
                # Tryggja a√∞ d√°lkheit s√©u strengir og unique
                cols = [str(c) for c in data.columns.tolist()]
                # Sumir JSON-reitir geta veri√∞ list/dict ‚Äî varpa √≠ streng fyrir Sheets
                df = data.copy()
                for c in df.columns:
                    df[c] = df[c].apply(lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, (list, dict)) else x)

                data_list = [cols] + df.values.tolist()
                cleaned_data = self.clean_data_for_sheets(data_list)
                try:
                    worksheet.update('A1', cleaned_data)
                    self.logger.info(f"‚úÖ Uppf√¶r√∞i {worksheet_name} me√∞ {len(df)} r√∂√∞um.")
                except Exception as e:
                    self.logger.error(f"üí• Villa vi√∞ uppf√¶rslu √° worksheet.update fyrir {worksheet_name}: {e}")
            else:
                self.logger.warning(f"‚ö†Ô∏è Engin g√∂gn til a√∞ uppf√¶ra √≠ {worksheet_name}.")
        except Exception as e:
            self.logger.error(f"üí• Villa vi√∞ a√∞ n√°lgast e√∞a b√∫a til sheet/worksheet: {e}")

    # --------------------------- Keyrsluf√∂ll ------------------------------- #
    def full_update(self):
        self.logger.info("üöÄ Byrja fulla uppf√¶rslu...")
        if not self.test_google_connection():
            self.logger.error("‚ùå Engin virk Google tenging.")
            return

        sheet_name = "PL_Fantasy_Data"

        # FBref
        league = self.get_premier_league_table()
        players = self.get_player_stats()
        fixtures = self.get_fixtures_and_results()

        if league is not None:
            self.update_google_sheet(sheet_name, league, "League_Table")
        if players is not None:
            self.update_google_sheet(sheet_name, players, "Player_Stats")
        if fixtures is not None:
            self.update_google_sheet(sheet_name, fixtures, "Fixtures_Results")

        # FPL (n√Ωtt!)
        fpl_dfs = self.get_fpl_data()
        for ws_name, df in fpl_dfs.items():
            self.update_google_sheet(sheet_name, df, ws_name)

        self.logger.info("‚úÖ Full uppf√¶rsla loki√∞!")

    def run_once(self):
        self.full_update()

    def start_scheduler(self):
        schedule.every(30).minutes.do(self.full_update)
        schedule.every().day.at("08:00").do(self.full_update)
        self.logger.info("‚è∞ Scheduler settur upp.")
        self.full_update()
        while True:
            schedule.run_pending()
            time.sleep(60)

# --------------------------- Einfaldur vef√æj√≥nn ---------------------------- #
def run_web_server():
    class Handler(SimpleHTTPRequestHandler):
        def do_GET(self):
            self.send_response(200)
            self.send_header('Content-type', 'text/html')
            self.end_headers()
            html = f"""
            <html>
            <head><title>PL Scraper</title></head>
            <body>
                <h1>‚úÖ PL Scraper √≠ gangi</h1>
                <p>S√≠√∞ast keyrt: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </body>
            </html>
            """
            self.wfile.write(html.encode('utf-8'))

    port = int(os.environ.get("PORT", 8000))
    server = HTTPServer(('0.0.0.0', port), Handler)
    thread = threading.Thread(target=server.serve_forever)
    thread.daemon = True
    thread.start()
    print(f"üåê Web server keyrir √° port {port}")

# --------------------------- main ----------------------------------------- #
def main():
    print("üöÄ R√¶si Premier League Scraper...")
    scraper = PremierLeagueScraper()
    if os.environ.get('RENDER') or os.environ.get('RAILWAY_ENVIRONMENT'):
        print("‚òÅÔ∏è Production mode")
        run_web_server()
        scraper.start_scheduler()
    else:
        print("üíª Development mode")
        scraper.run_once()

if __name__ == "__main__":
    main()
